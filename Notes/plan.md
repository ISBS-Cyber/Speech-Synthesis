## Slid plan

1. Title (To what extent does AI-Driven voice banking VOCAS preserve the identity and autonomy with people with MND? - but make that clearer and less wordy)
2. What is MND speech impairment problem, how can Speech Synth help
3. Technical understanding of speech synthesis
4. Technical applications within Voice Banking and what features of modern models/approaches are most fit for purpose here
5. Discussion on ability of making accurate voice representation with low amount of voice samples (potentially falling into reduced coverage and overfitting)
6. Challange of how digital acoustic similarity does not directly mean preserving identity etc. 
7. how realistically can this technology be used by an MND person, (speed of computing/use, compatibility with switches etc)
8. Use of concepts like Transfer learning (or equivalent to speed up personalising TTS)
9. Development of naturalness in newer models (link back to how naturalness may not always mean emotionally representative etc)
10. Robustness and reliability of Speech synth models
11. Qualitative feedback on voice banking from user of it
12. Honest evaluation of Voice Banking powered VOCAS, specifically if SS is valuable
13. Future for this technology
14. Future research (large studies)