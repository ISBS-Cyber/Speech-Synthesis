1. Title (To what extent does AI-Driven voice banking VOCAS preserve the identity and autonomy with people with MND? - but make that clearer and less wordy)
2. What is MND Voice loss problem, how can Speech Synth help
3. Technical understanding of speech synthesis
4. Technical aplications within Voice Banking and what features of modern models/approaches are most fit for purpose here
5. Discussion on ability of making accurate voice representation with low ammount of voice samples (potentially falling into reduced coverage and overfitting)
6. Challange of how digital acoustic similarity does not directly mean preserving identity etc. 
7. how realistically can this technology be used by an MND person, (speed of computing/use, compatibility with switches etc)
8. Use of concepts like Transfer learning (or equivalent to speed up personalising TTS)
9. Development of naturalness in newer models (link back to how naturalness may not always mean emotionally representative etc)
10. (Person handling this section add here)
11. Scores of quantitative performance of SS models
12. Robustness and reliability of Speech synth models
13. Qualitative feedback on voice banking from user of it
14. Honest evaluation of Voice Banking powered VOCAS, specifically if SS is valuble
15. Future for this technology