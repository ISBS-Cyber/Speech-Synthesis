@misc{Michel2025,
  title         = {"It's not a representation of me": Examining Accent Bias and Digital Exclusion in Synthetic AI Voice Services},
  author        = {Shira Michel and Sufi Kaur and Sarah Elizabeth Gillespie and Jeffrey Gleason and Christo Wilson and Avijit Ghosh},
  year          = {2025},
  eprint        = {2504.09346},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2504.09346}
}

@inproceedings{Valencia2023,
  author    = {Valencia, Stephanie and Cave, Richard and Kallarackal, Krystal and Seaver, Katie and Terry, Michael and Kane, Shaun K.},
  title     = {“The less I type, the better”: How AI Language Models can Enhance or Impede Communication for AAC Users},
  year      = {2023},
  isbn      = {9781450394215},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3544548.3581560},
  doi       = {10.1145/3544548.3581560},
  abstract  = {Users of augmentative and alternative communication (AAC) devices sometimes find it difficult to communicate in real time with others due to the time it takes to compose messages. AI technologies such as large language models (LLMs) provide an opportunity to support AAC users by improving the quality and variety of text suggestions. However, these technologies may fundamentally change how users interact with AAC devices as users transition from typing their own phrases to prompting and selecting AI-generated phrases. We conducted a study in which 12 AAC users tested live suggestions from a language model across three usage scenarios: extending short replies, answering biographical questions, and requesting assistance. Our study participants believed that AI-generated phrases could save time, physical and cognitive effort when communicating, but felt it was important that these phrases reflect their own communication style and preferences. This work identifies opportunities and challenges for future AI-enhanced AAC devices.},
  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  articleno = {830},
  numpages  = {14},
  keywords  = {accessibility, artificial intelligence, communication, large language models},
  location  = {Hamburg, Germany},
  series    = {CHI '23}
}

@article{Cave2021,
  title     = {Voice banking for people living with motor neurone disease: Views and expectations},
  author    = {Cave, Richard and Bloch, Steven},
  journal   = {International Journal of Language \& Communication Disorders},
  volume    = {56},
  number    = {1},
  pages     = {116--129},
  year      = {2021},
  publisher = {Wiley Online Library}
}


@article{Barry2025,
  author         = {Barry, Ian and El-Wahsh, Sarah},
  title          = {Banking on My Voice: Life with Motor Neurone Disease},
  journal        = {Healthcare},
  volume         = {13},
  year           = {2025},
  number         = {14},
  article-number = {1770},
  url            = {https://www.mdpi.com/2227-9032/13/14/1770},
  pubmedid       = {40724795},
  issn           = {2227-9032},
  abstract       = {This perspective paper presents a first-person account of life with motor neurone disease (MND). Through the lens of lived experience, it explores the complex and often prolonged diagnostic journey, shaped in part by the protective grip of denial. This paper then delves into the emotional impact of MND on the individual and their close relationships, capturing the strain on identity and family dynamics. It also highlights the vital role of the multidisciplinary team in providing support throughout the journey. A central focus of the paper is the personal journey of voice banking. It reflects on the restorative experience of reclaiming a pre-disease voice through tools such as ElevenLabsTM. This narrative underscores the critical importance of early intervention and timely access to voice banking, positioning voice not only as a tool for communication but also as a powerful anchor of identity, dignity, and agency. The paper concludes by highlighting key systemic gaps in MND care. It calls for earlier referral to speech pathology, earlier access to voice banking, access to psychological support from the time of diagnosis, and better integration between research and clinical care.},
  doi            = {10.3390/healthcare13141770}
}

@article{Leite2017,
  title={Dysarthria and quality of life in patients with amyotrophic lateral sclerosis},
  author={Leite, Lavoisier and Constantini, Ana Carolina},
  journal={Revista CEFAC},
  volume={19},
  pages={664--673},
  year={2017},
  publisher={SciELO Brasil}
}


@article{Jackson2025,
  title={Stage-Based Communication Rehabilitation in Amyotrophic Lateral Sclerosis (ALS): A Review of Strategies for Enhancing Quality of Life},
  author={Jackson, Mark C and Azarraga, Rafaelle B and Fraix, Marcel P and Agrawal, Devendra K},
  journal={Archives of internal medicine research},
  volume={8},
  number={4},
  pages={359},
  year={2025}
}

@article{elsahar2019augmentative,
  title     = {Augmentative and alternative communication (AAC) advances: A review of configurations for individuals with a speech disability},
  author    = {Elsahar, Yasmin and Hu, Sijung and Bouazza-Marouf, Kaddour and Kerr, David and Mansor, Annysa},
  journal   = {Sensors},
  volume    = {19},
  number    = {8},
  pages     = {24},
  year      = {2019},
  publisher = {MDPI}
}

@article{tan2021survey,
  title   = {A survey on neural speech synthesis},
  author  = {Tan, Xu and Qin, Tao and Soong, Frank and Liu, Tie-Yan},
  journal = {arXiv preprint arXiv:2106.15561},
  year    = {2021}
}

@article{nhsPowerpoint,
  title  = {Voice Banking, Message Banking, Digital Legacy},
  author = {Archer, Mary and Murphy, Siobhan},
  year   = {2019}
} %TODO make these references contain author

@article{sixthNervePalsy,
  title  = {Sixth Nerve Palsy},
  author = {Cleaveland Clinic},
  year   = {2023}
} %TODO make these references contain author

@misc{zhou2024thu,
  author = {Yixuan Zhou and Shuoyi Zhou and Shun Lei and Zhiyong Wu and Menglin Wu},
  title  = {The THU-HCSI Multi-Speaker Multi-Lingual Few-Shot Voice Cloning System for LIMMITS'24 Challenge},
  year   = {2024},
  note   = {Retrieved February 18, 2026},
  url    = {https://arxiv.org/pdf/2404.16619}
}

@inproceedings{peng2024voicecraft,
  author    = {Puyuan Peng and Po-Yao Huang and Shang-Wen Li and Abdelrahman Mohamed and David Harwath},
  title     = {VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild},
  booktitle = {Proceedings of ACL},
  year      = {2024},
  pages     = {12442--12462},
  url       = {https://aclanthology.org/2024.acl-long.673.pdf}
}

@misc{chen2024humanfeedback,
  author = {Chen Chen and Yuchen Hu and Wen Wu and Helin Wang and Eng Chng and Chao Zhang},
  title  = {Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback},
  year   = {2024},
  note   = {Retrieved February 18, 2026},
  url    = {https://arxiv.org/pdf/2406.00654}
}

@misc{ieee2018mnd,
  author = {Disong Wang, Songxiang Liu, Xixin Wu, Hui Lu, Lifa Sun, Xunying Liu, Helen Meng},
  title = {SPEAKER IDENTITY PRESERVATION IN DYSARTHRIC SPEECH RECONSTRUCTION BY ADVERSARIAL SPEAKER ADAPTATION},
  year  = {2022},
  note  = {Retrieved February 19, 2026},
  url   = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746680}
} 

@article{mandeel2022speaker,
  author  = {Ali Raheem Mandeel and Mohammed Salah Al-Radhi and Tamás Gábor Csapó},
  title   = {Speaker Adaptation Experiments with Limited Data for End-to-End Text-To-Speech Synthesis using Tacotron2},
  journal = {Infocommunications Journal},
  volume  = {14},
  number  = {3},
  pages   = {55--62},
  year    = {2022},
  doi     = {10.36244/icj.2022.3.7}
}

@misc{ieee2018streams,
  author = {Georgi Shopov, Stefan Gerdjikov, Stoyan Mihov},
  title = {STREAMSPEECH: LOW-LATENCY NEURAL ARCHITECTURE FOR HIGH-QUALITY ON-DEVICE SPEECH SYNTHESIS},
  year  = {2023},
  note  = {Retrieved February 20, 2026},
  url   = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10096566}
}

@article{oord2016wavenet,
  author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and 
            Simonyan, Karen and Vinyals, Oriol and Graves, Alex and 
            Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  title = {WaveNet: A Generative Model for Raw Audio},
  journal = {arXiv preprint arXiv:1609.03499},
  year = {2016},
  url = {https://arxiv.org/abs/1609.03499}
}

@article{shen2017tacotron2,
  author = {Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and 
            Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and 
            Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and 
            Skerrv-Ryan, R. J. and others},
  title = {Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions},
  journal = {arXiv preprint arXiv:1712.05884},
  year = {2017},
  url = {https://arxiv.org/abs/1712.05884}
}

@article{kim2021vits,
  author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  title = {Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech},
  journal = {arXiv preprint arXiv:2106.06103},
  year = {2021},
  url = {https://arxiv.org/abs/2106.06103}
}

@article{survey2023diffusion,
  author = {Liu, Xubo and others},
  title = {A Survey on Audio Diffusion Models: Text-to-Speech Synthesis and Beyond},
  journal = {arXiv preprint arXiv:2303.13336},
  year = {2023},
  url = {https://arxiv.org/abs/2303.13336}
}

@article{lrspeech2020,
  author = {Luo, Yi and others},
  title = {LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition},
  journal = {arXiv preprint arXiv:2008.03687},
  year = {2020},
  url = {https://arxiv.org/abs/2008.03687}
}

@article{zhang2024multilingual,
  author = {Zhang, Ziqiang and others},
  title = {Extending Multilingual Speech Synthesis to 100+ Languages},
  journal = {arXiv preprint arXiv:2402.18932},
  year = {2024},
  url = {https://arxiv.org/abs/2402.18932}
}

@article{wang2023valle,
  author = {Wang, Chengyi and others},
  title = {Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers},
  journal = {arXiv preprint arXiv:2301.02111},
  year = {2023},
  url = {https://arxiv.org/abs/2301.02111}
}

@misc{tacotron2_blog,
  author = {Google AI Blog},
  title = {Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions (Tacotron 2)},
  howpublished = {\url{https://google.github.io/tacotron/publications/tacotron2/}},
  year = {2017},
  note = {Observed occasional long-form instability in demo outputs}
}

@inproceedings{fakir2025tts,
  author = {El Fakir, Zakaria and Kaich, Oussama and others},
  title = {TTS and STT in Service of Education},
  booktitle = {Proceedings of the 7th International Conference on Advanced Technologies for Humanity (ICATH 2025)},
  year = {2025},
  publisher = {MDPI},
  doi = {10.3390/engproc2025112004},
  url = {https://doi.org/10.3390/engproc2025112004}
}
